{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06a6416-6ccd-424a-8c21-da019cfdefc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login do SEI:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " daiana.sales\n",
      "Digite sua senha (não vai aparecer na tela):  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seu acesso foi realizado com sucesso!\n",
      "Concluído\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# busca todos os arquivos período explícito sem especificar a data\n",
    "#########################################################################\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time, getpass\n",
    "from bs4 import  BeautifulSoup\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "def build_path(subfolder):\n",
    "    current_folder = os.getcwd()\n",
    "    folderpath = os.path.join(current_folder, subfolder)\n",
    "    folderpath = os.path.abspath(folderpath)\n",
    "    if not os.path.exists(folderpath): os.makedirs(folderpath)\n",
    "    return folderpath\n",
    "\n",
    "build_path('arquivos')\n",
    "\n",
    "# login page\n",
    "\n",
    "def DigitaNaCaixaId(idCaixa, Texto):\n",
    "  global driver\n",
    "  Caixa = driver.find_element_by_id(idCaixa)\n",
    "  Caixa.clear()\n",
    "  Caixa.send_keys(Texto)\n",
    "\n",
    "def UsuarioDigitaLoginEsenha():\n",
    "  global LoginUsuario, Senha\n",
    "  print('Login do SEI:')\n",
    "  LoginUsuario = input()\n",
    "  Senha = getpass.getpass(\"Digite sua senha (não vai aparecer na tela): \")\n",
    "\n",
    "def FazLogin():\n",
    "  global driver, WebEspera\n",
    "  global LoginUsuario, Senha\n",
    "  url = 'https://sip.sgb.gov.br/sip/login.php?sigla_orgao_sistema=CPRM&sigla_sistema=SEI&infra_url=L3NlaS8='\n",
    "  driver = webdriver.Edge('C:\\Program Files\\Edge\\msedgedriver.exe')\n",
    "  driver.implicitly_wait(10)\n",
    "  driver.get(url)\n",
    "  driver.maximize_window()\n",
    "  WebEspera = WebDriverWait(driver, 20)\n",
    "  \n",
    "  DigitaNaCaixaId('txtUsuario', LoginUsuario)\n",
    "  time.sleep(1)\n",
    "  DigitaNaCaixaId('pwdSenha', Senha)\n",
    "  time.sleep(1)\n",
    "\n",
    "  # ContagemRegressiva(TempoEsperaLogin)\n",
    "\n",
    "  LoginEnter = driver.find_element(\"xpath\", '//*[@id=\"sbmLogin\"]')\n",
    "  LoginEnter.click()\n",
    "  time.sleep(2)\n",
    "# Fim FazLogin()\n",
    "\n",
    "UsuarioDigitaLoginEsenha()\n",
    "FazLogin()\n",
    "print('Seu acesso foi realizado com sucesso!')\n",
    "\n",
    "\n",
    "# home page\n",
    "\n",
    "searching = driver.find_element(\"xpath\", '//*[@id=\"main-menu\"]/li[5]/a')\n",
    "searching.click()\n",
    "\n",
    "# search page\n",
    "\n",
    "doc_type = driver.find_element(\"xpath\", '//*[@id=\"selSeriePesquisa\"]')\n",
    "doc_date_explicit = driver.find_element(\"xpath\", '//*[@id=\"optPeriodoExplicito\"]')\n",
    "sub_button = driver.find_element(\"xpath\", '//*[@id=\"sbmPesquisar\"]')\n",
    "\n",
    "doc_type.send_keys('REMA - Empréstimo de Materiais ou Ex. Geológicos')\n",
    "doc_date_explicit.click()\n",
    "sub_button.click()\n",
    "\n",
    "\n",
    "#################################################\n",
    "def get_files():\n",
    "\n",
    "    original_window = driver.current_window_handle \n",
    "    page_docs_search = driver.find_element_by_xpath('//*[@id=\"conteudo\"]')  # Corrigido de \"driver.find_element\" para \"driver.find_element_by_xpath\"\n",
    "    page_docs = page_docs_search.text.split('Atividade Fim: ')[1:]\n",
    "\n",
    "    file_name = []\n",
    "    for i in range(len(page_docs)):\n",
    "        a = page_docs[i].split('(REMA - Empréstimo de Materiais ou Ex. Geológicos) ')[1].split('\\n1')[0]\n",
    "        file_name.append(a)\n",
    "\n",
    "    links = []\n",
    "    for i in range(1, len(page_docs)+1):\n",
    "        a = driver.find_element_by_xpath(f'//*[@id=\"conteudo\"]/table[{i}]/tbody/tr[1]/td[1]/a[2]')\n",
    "        link = a.get_attribute('href')\n",
    "        links.append(link)\n",
    "    \n",
    "    for i in links:\n",
    "        name = file_name[links.index(i)]  # Corrigido para encontrar o índice correto\n",
    "        driver.execute_script(\"window.open('');\")  # Alterado para a abertura de uma nova aba\n",
    "        driver.switch_to.window(driver.window_handles[1])  # Mudado para o índice 1\n",
    "        driver.get(i)\n",
    "        with open(f'./arquivos/processo{name}.html', 'w', encoding='iso-8859-1') as file:  # Corrigido a string de formatação e a sintaxe de abertura de arquivo\n",
    "            file.write(driver.page_source)        \n",
    "        driver.close()\n",
    "        driver.switch_to.window(original_window) \n",
    "  \n",
    "\n",
    "#################################################\n",
    "\n",
    "# pagination \n",
    "\n",
    "pages = driver.find_element(by=By.CLASS_NAME, value=\"paginas\")\n",
    "list_pages = pages.text.split(' ')[:-1]\n",
    "\n",
    "get_files()\n",
    "\n",
    "for i in range(1, len(list_pages)):\n",
    "    \n",
    "    try:\n",
    "        next_page = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/div[2]/a[%s]' %i)\n",
    "        next_page.click()\n",
    "        time.sleep(6)\n",
    "        get_files()\n",
    "    except (NameError, TypeError):\n",
    "        pass\n",
    "    time.sleep(3)  \n",
    "    \n",
    "\n",
    "driver.close()\n",
    "driver.quit()\n",
    "\n",
    "### Rrtirar dados do html para a planilha\n",
    "\n",
    "pasta = f'arquivos'\n",
    "arquivo = os.listdir(pasta)\n",
    "fname = [pasta +'/'+ arq for arq in arquivo if arq.endswith(\".html\")]\n",
    "\n",
    "\n",
    "lista_df=[]\n",
    "\n",
    "for i in fname:\n",
    "\n",
    "    with open(i, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "        soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "\n",
    "    tags = [tag for tag in soup.find(\"div\", id=\"conteudo\").children if len(tag.text.strip()) > 0 and not re.match(r\"^\\d+\\.\", tag.text.strip())]\n",
    "    # Cada HTML, um dicionário ordenado\n",
    "    dict_series = OrderedDict()\n",
    "\n",
    "    for index in range(len(tags)):\n",
    "        tag = tags[index]\n",
    "        \n",
    "        if tag.name == \"b\":\n",
    "            key = tag.text.strip().rstrip(\":\")\n",
    "            value = tags[index + 1].text.strip()\n",
    "            \n",
    "            dict_series[key] = value\n",
    "\n",
    "\n",
    "    # Empilhar todos os dicionários para criar o df e interpretar os dtypes\n",
    "    df = (\n",
    "        pd.DataFrame([dict_series])\n",
    "            .apply(lambda x: pd.to_numeric(x.str.replace(\",\", \".\"), errors=\"ignore\"))\n",
    "            .apply(lambda x: x.replace(\"Sim\", True).replace(\"Não\", False))        \n",
    "    )\n",
    "    lista_df.append(df)\n",
    "\n",
    "DataFrame=pd.concat(lista_df,ignore_index=index)\n",
    "DataFrame\n",
    "\n",
    "DataFrame.to_excel('C:/Users/Rosana/Desktop/SEI/REMA.xlsx', index=False)\n",
    "\n",
    "print(\"Concluído\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
